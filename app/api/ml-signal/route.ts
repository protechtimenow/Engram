import { NextRequest, NextResponse } from "next/server";
import { exec } from "child_process";
import { promisify } from "util";
import * as path from "path";
import * as fs from "fs";

const execAsync = promisify(exec);
const R_MODELS_DIR = path.join(process.cwd(), "src", "r_models");
const SIGNALS_DIR = path.join(R_MODELS_DIR, "signals");

interface MLSignal {
  symbol: string;
  timestamp: string;
  current_price: number;
  signal: "BUY" | "SELL" | "HOLD";
  confidence: number;
  probabilities: {
    buy: number;
    sell: number;
    hold: number;
  };
  features: {
    sma7_ratio: number;
    momentum_7: number;
    volatility: number;
  };
  model_type: string;
  recommendation: string;
}

async function runRModel(symbol: string): Promise<MLSignal | null> {
  try {
    // Ensure signals directory exists
    if (!fs.existsSync(SIGNALS_DIR)) {
      fs.mkdirSync(SIGNALS_DIR, { recursive: true });
    }

    // Run Python wrapper that calls R
    const scriptPath = path.join(R_MODELS_DIR, "run_model.py");
    const { stdout, stderr } = await execAsync(
      `python "${scriptPath}" ${symbol}`,
      { timeout: 300000, cwd: R_MODELS_DIR } // 5 min timeout
    );

    if (stderr && !stderr.includes("Warning")) {
      console.error("R Model stderr:", stderr);
    }

    // Read the generated signal
    const signalFile = path.join(SIGNALS_DIR, `${symbol}_signal.json`);
    
    if (!fs.existsSync(signalFile)) {
      console.error("Signal file not found:", signalFile);
      return null;
    }

    const signalData = JSON.parse(fs.readFileSync(signalFile, "utf8"));
    return signalData as MLSignal;

  } catch (error) {
    console.error("Failed to run R model:", error);
    return null;
  }
}

export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const symbol = searchParams.get("symbol") || "BTCUSDT";
    const format = searchParams.get("format") || "json";

    console.log(`Generating ML signal for ${symbol}...`);

    const signal = await runRModel(symbol);

    if (!signal) {
      return NextResponse.json(
        { error: "Failed to generate ML signal" },
        { status: 500 }
      );
    }

    if (format === "a2a") {
      // Format for A2A debate input
      const a2aPrompt = `
ðŸ§  ML MODEL ANALYSIS (tidymodels Random Forest):

Asset: ${signal.symbol} @ $${signal.current_price}
ML Signal: ${signal.signal} (confidence: ${(signal.confidence * 100).toFixed(1)}%)

Model Probabilities:
- BUY: ${(signal.probabilities.buy * 100).toFixed(1)}%
- SELL: ${(signal.probabilities.sell * 100).toFixed(1)}%
- HOLD: ${(signal.probabilities.hold * 100).toFixed(1)}%

Technical Features:
- Price/SMA7 Ratio: ${signal.features.sma7_ratio.toFixed(4)}
- 7-Day Momentum: ${(signal.features.momentum_7 * 100).toFixed(2)}%
- Volatility: ${signal.features.volatility.toFixed(4)}

ML Recommendation: ${signal.recommendation}

---
This signal was generated by a Random Forest model trained on 90 days of price data using tidymodels. Evaluate this signal alongside technical analysis and market context before making any trading decisions.
`;

      return NextResponse.json({
        success: true,
        format: "a2a",
        symbol: signal.symbol,
        signal: signal.signal,
        confidence: signal.confidence,
        prompt: a2aPrompt,
        raw_data: signal
      });
    }

    // Standard JSON format
    return NextResponse.json({
      success: true,
      data: signal,
      generated_at: new Date().toISOString()
    });

  } catch (error) {
    console.error("ML Signal API Error:", error);
    return NextResponse.json(
      { error: "Internal server error" },
      { status: 500 }
    );
  }
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { symbol, run_a2a } = body;

    if (!symbol) {
      return NextResponse.json(
        { error: "Missing symbol parameter" },
        { status: 400 }
      );
    }

    const signal = await runRModel(symbol);

    if (!signal) {
      return NextResponse.json(
        { error: "Failed to generate ML signal" },
        { status: 500 }
      );
    }

    // Optionally run A2A debate with the signal
    if (run_a2a) {
      // Forward to A2A debate API
      const a2aResponse = await fetch(`${request.nextUrl.origin}/api/a2a/debate`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          action: "start",
          topic: `${symbol} ML Signal Analysis`,
          context: `ML Model generated a ${signal.signal} signal for ${symbol} at $${signal.current_price} with ${(signal.confidence * 100).toFixed(1)}% confidence. Probabilities: BUY ${(signal.probabilities.buy * 100).toFixed(1)}%, SELL ${(signal.probabilities.sell * 100).toFixed(1)}%, HOLD ${(signal.probabilities.hold * 100).toFixed(1)}%.`,
          asset: symbol.replace("USDT", ""),
          price: signal.current_price
        })
      });

      const a2aResult = await a2aResponse.json();

      return NextResponse.json({
        success: true,
        ml_signal: signal,
        a2a_debate: a2aResult,
        integration: "ML + A2A Complete"
      });
    }

    return NextResponse.json({
      success: true,
      data: signal
    });

  } catch (error) {
    console.error("ML Signal API Error:", error);
    return NextResponse.json(
      { error: "Internal server error" },
      { status: 500 }
    );
  }
}
