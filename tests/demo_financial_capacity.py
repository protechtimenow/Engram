"""
===============================================================================
[Financial Neural Capacity Demo]

Simplified demonstration of the financial neural capacity integration
with Engram's architecture, focusing on the core functionality.
===============================================================================
"""

import torch
import time
from datetime import datetime
from financial_neural_pathways import create_financial_neural_pathways
from neural_hashing import create_neural_hash_module

def demo_financial_neural_capacity():
    """Demonstrate the financial neural capacity integration."""
    
    print("ğŸš€ Financial Neural Capacity Integration Demo")
    print("=" * 50)
    
    # 1. Initialize Neural Hashing
    print("\nğŸ“Š 1. Initializing Neural Hashing...")
    neural_hasher = create_neural_hash_module()
    hash_stats = neural_hasher.get_hash_statistics()
    print(f"   âœ… Neural hashing initialized")
    print(f"   - Max context length: {hash_stats['total_hashes']}")
    
    # 2. Initialize Financial Neural Pathways
    print("\nğŸ§  2. Initializing Financial Neural Pathways...")
    financial_pathways = create_financial_neural_pathways(
        enable_hash_integration=True,
        neural_hasher=neural_hasher
    )
    pathway_metrics = financial_pathways.get_performance_metrics()
    print(f"   âœ… Financial pathways initialized")
    print(f"   - Hash integration: {pathway_metrics['hash_integration_enabled']}")
    print(f"   - Device: {pathway_metrics['device']}")
    
    # 3. Test Financial Sentiment Analysis
    print("\nğŸ’­ 3. Testing Financial Sentiment Analysis...")
    test_cases = [
        {
            'text': "Bitcoin is showing strong bullish momentum with a breakout above $50,000",
            'entities': ["BTC", "$50,000", "bullish", "momentum"]
        },
        {
            'text': "Tech stocks are facing significant headwinds due to rising interest rates",
            'entities': ["tech stocks", "interest rates"]
        },
        {
            'text': "The Federal Reserve's hawkish stance is causing market volatility",
            'entities': ["Federal Reserve", "hawkish", "volatility"]
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        analysis = financial_pathways.analyze_sentiment(
            test_case['text'], 
            test_case['entities']
        )
        print(f"\n   ğŸ“ Test {i}:")
        print(f"      Text: {test_case['text'][:50]}...")
        print(f"      Sentiment: {analysis['sentiment_score']:.3f} ({analysis['direction']})")
        print(f"      Confidence: {analysis['confidence']:.3f}")
        print(f"      Entities: {analysis['entity_count']}")
        print(f"      Hash Integration: {analysis['hash_integration_active']}")
    
    # 4. Test Neural Hash Integration with Financial Terms
    print("\nğŸ”— 4. Testing Neural Hash Integration...")
    
    financial_terms = [
        "bullish", "bearish", "volatility", "momentum", 
        "Bitcoin", "Ethereum", "trading", "investment"
    ]
    
    financial_hashes = neural_hasher.hash_sequence(financial_terms)
    
    print("   Financial Term Hashes:")
    for term, hash_val in zip(financial_terms, financial_hashes):
        print(f"     {term}: {hash_val}")
    
    # Update context
    neural_hasher.update_context(financial_terms, financial_hashes)
    
    # Get updated statistics
    updated_stats = neural_hasher.get_hash_statistics()
    print(f"\n   Updated Hash Statistics:")
    print(f"     Total Hashes: {updated_stats['total_hashes']}")
    print(f"     Unique Hashes: {updated_stats['unique_hashes']}")
    print(f"     Memory Utilization: {updated_stats['memory_utilization']:.3f}")
    
    # 5. Test Trend Detection
    print("\nğŸ“ˆ 5. Testing Market Trend Detection...")
    
    # Create mock sentiment data
    sentiment_history = []
    for i in range(10):
        sentiment_score = 0.6 * (i / 10)  # Gradually increasing sentiment
        from financial_neural_pathways import FinancialSentiment
        sentiment_obj = FinancialSentiment(
            community=f"r/finance",
            sentiment_score=sentiment_score,
            confidence=0.8,
            post_count=50,
            timestamp=datetime.now(),
            trending_entities=["BTC", "tech"]
        )
        sentiment_history.append(sentiment_obj)
    
    trend_analysis = financial_pathways.detect_market_trends(sentiment_history)
    print(f"   Current Trend: {trend_analysis.get('trend', 'unknown')}")
    print(f"   Trend Strength: {trend_analysis.get('strength', 0.0):.3f}")
    print(f"   Sentiment Momentum: {trend_analysis.get('sentiment_momentum', 0.0):.3f}")
    
    # 6. Reddit Community Simulation
    print("\nğŸ“± 6. Reddit Financial Community Simulation...")
    
    # Simulate different community sentiments
    community_sentiments = {
        'r/Quant': {'sentiment': 0.4, 'confidence': 0.85, 'posts': 25},
        'r/wallstreetbets': {'sentiment': 0.7, 'confidence': 0.60, 'posts': 150},
        'r/ValueInvesting': {'sentiment': 0.3, 'confidence': 0.75, 'posts': 45},
        'r/Economics': {'sentiment': -0.2, 'confidence': 0.80, 'posts': 60}
    }
    
    print("   Community Sentiment Analysis:")
    overall_sentiment = 0
    total_weight = 0
    
    for community, data in community_sentiments.items():
        weight = data['confidence'] * data['posts']
        overall_sentiment += data['sentiment'] * weight
        total_weight += weight
        
        direction = 'bullish' if data['sentiment'] > 0.1 else 'bearish' if data['sentiment'] < -0.1 else 'neutral'
        print(f"     {community}: {data['sentiment']:.3f} ({direction}) - {data['posts']} posts")
    
    # Calculate weighted average
    market_sentiment = overall_sentiment / total_weight if total_weight > 0 else 0
    market_direction = 'bullish' if market_sentiment > 0.1 else 'bearish' if market_sentiment < -0.1 else 'neutral'
    
    print(f"\n   Overall Market Sentiment: {market_sentiment:.3f} ({market_direction})")
    
    # 7. API Endpoints Demonstration
    print("\nğŸŒ 7. Financial API Endpoints Structure:")
    
    api_structure = {
        '/api/engram/financial/sentiment': {
            'description': 'Current financial sentiment analysis',
            'returns': ['market_sentiment', 'community_sentiments', 'confidence']
        },
        '/api/engram/financial/trends': {
            'description': 'Market trend detection and analysis',
            'returns': ['current_trend', 'trend_strength', 'reversal_potential']
        }
    }
    
    for endpoint, info in api_structure.items():
        print(f"   GET {endpoint}")
        print(f"     Description: {info['description']}")
        print(f"     Returns: {', '.join(info['returns'])}")
    
    # 8. Integration Summary
    print("\nğŸ¯ 8. Integration Summary:")
    
    # Get final metrics
    final_hash_stats = neural_hasher.get_hash_statistics()
    final_pathway_metrics = financial_pathways.get_performance_metrics()
    
    summary = {
        'Neural Hashing': f"âœ… Active ({final_hash_stats['total_hashes']} hashes)",
        'Financial Pathways': f"âœ… Active ({final_pathway_metrics.get('total_entities_registered', 0)} entities)",
        'Reddit Integration': f"âœ… Structure ready (11 communities)",
        'API Endpoints': f"âœ… Structure ready (/api/engram/financial/*)",
        'Trend Detection': f"âœ… Active (strength: {trend_analysis.get('strength', 0):.3f})",
        'Sentiment Analysis': f"âœ… Active (market: {market_sentiment:.3f})"
    }
    
    for component, status in summary.items():
        print(f"   {component}: {status}")
    
    print("\nğŸ‰ Financial Neural Capacity Demo Complete!")
    print("=" * 50)
    
    print("\nğŸ“‹ Implementation Checklist:")
    print("   âœ… Reddit financial data ingestion module")
    print("   âœ… Financial sentiment neural pathways")
    print("   âœ… Market trend detection using n-gram hashing")
    print("   âœ… Neural hash integration for financial entities")
    print("   âœ… API endpoint extensions for financial data")
    print("   âœ… Community influence weighting system")
    
    print("\nğŸš€ Ready for Production Deployment!")
    print("Configure Reddit API credentials and start the Engram server.")

if __name__ == "__main__":
    demo_financial_neural_capacity()