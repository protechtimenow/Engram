#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test suite for Enhanced Engram Launcher V2
Validates LMStudio integration, retry logic, and fallback mechanisms
"""

import sys
import json
import logging
import time
from pathlib import Path
from datetime import datetime

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EnhancedLauncherTests:
    """Test suite for enhanced launcher"""
    
    def __init__(self):
        self.tests_passed = 0
        self.tests_failed = 0
        self.test_results = []
        
    def record_test(self, name: str, passed: bool, details: str = ""):
        """Record test result"""
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        logger.info(f"{status}: {name} - {details}")
        
        self.test_results.append({
            "test_name": name,
            "passed": passed,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })
        
        if passed:
            self.tests_passed += 1
        else:
            self.tests_failed += 1
            
    def test_imports(self) -> bool:
        """Test 1: Verify all imports work"""
        logger.info("üß™ Test 1: Import Validation")
        try:
            import requests
            import json
            from pathlib import Path
            self.record_test("Import Validation", True, "All required modules available")
            return True
        except Exception as e:
            self.record_test("Import Validation", False, f"Import error: {e}")
            return False
            
    def test_config_loading(self) -> bool:
        """Test 2: Configuration loading"""
        logger.info("üß™ Test 2: Configuration Loading")
        try:
            config_path = Path(__file__).parent / "config" / "telegram" / "working_telegram_config.json"
            
            if not config_path.exists():
                self.record_test("Config Loading", False, f"Config not found: {config_path}")
                return False
                
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                
            # Validate structure
            if 'telegram' not in config:
                self.record_test("Config Loading", False, "Missing 'telegram' section")
                return False
                
            telegram = config['telegram']
            if 'bot_token' not in telegram or 'chat_id' not in telegram:
                self.record_test("Config Loading", False, "Missing credentials")
                return False
                
            self.record_test("Config Loading", True, f"Config loaded with chat_id: {telegram['chat_id']}")
            return True
            
        except Exception as e:
            self.record_test("Config Loading", False, f"Error: {e}")
            return False
            
    def test_lmstudio_client_init(self) -> bool:
        """Test 3: LMStudio client initialization"""
        logger.info("üß™ Test 3: LMStudio Client Initialization")
        try:
            # Import the enhanced launcher
            sys.path.insert(0, str(Path(__file__).parent))
            from enhanced_engram_launcher_v2 import LMStudioClient
            
            client = LMStudioClient(
                base_url="http://192.168.56.1:1234",
                timeout=60,
                max_retries=3
            )
            
            if client.base_url and client.timeout and client.max_retries:
                self.record_test("LMStudio Client Init", True, "Client initialized with correct parameters")
                return True
            else:
                self.record_test("LMStudio Client Init", False, "Missing parameters")
                return False
                
        except Exception as e:
            self.record_test("LMStudio Client Init", False, f"Error: {e}")
            return False
            
    def test_mock_ai_analyzer(self) -> bool:
        """Test 4: Mock AI analyzer"""
        logger.info("üß™ Test 4: Mock AI Analyzer")
        try:
            from enhanced_engram_launcher_v2 import MockAIAnalyzer
            
            analyzer = MockAIAnalyzer()
            
            # Test analysis
            result = analyzer.analyze("Analyze BTC/USDT")
            if result and len(result) > 50:
                self.record_test("Mock AI Analyzer", True, f"Generated analysis: {len(result)} chars")
                return True
            else:
                self.record_test("Mock AI Analyzer", False, "Analysis too short or empty")
                return False
                
        except Exception as e:
            self.record_test("Mock AI Analyzer", False, f"Error: {e}")
            return False
            
    def test_mock_ai_chat(self) -> bool:
        """Test 5: Mock AI chat responses"""
        logger.info("üß™ Test 5: Mock AI Chat")
        try:
            from enhanced_engram_launcher_v2 import MockAIAnalyzer
            
            analyzer = MockAIAnalyzer()
            
            # Test different message types
            test_messages = [
                ("hello", "greeting"),
                ("help", "help request"),
                ("what is bitcoin", "bitcoin query"),
                ("random message", "general message")
            ]
            
            all_passed = True
            for message, msg_type in test_messages:
                result = analyzer.chat(message)
                if not result or len(result) < 10:
                    all_passed = False
                    logger.warning(f"Failed for {msg_type}")
                    
            if all_passed:
                self.record_test("Mock AI Chat", True, f"All {len(test_messages)} message types handled")
                return True
            else:
                self.record_test("Mock AI Chat", False, "Some message types failed")
                return False
                
        except Exception as e:
            self.record_test("Mock AI Chat", False, f"Error: {e}")
            return False
            
    def test_retry_logic(self) -> bool:
        """Test 6: Retry logic with exponential backoff"""
        logger.info("üß™ Test 6: Retry Logic")
        try:
            from enhanced_engram_launcher_v2 import LMStudioClient
            
            client = LMStudioClient(
                base_url="http://192.168.56.1:1234",
                timeout=5,  # Short timeout for testing
                max_retries=3
            )
            
            # This should fail but test the retry mechanism
            start_time = time.time()
            result = client.query("test prompt")
            elapsed = time.time() - start_time
            
            # Should have tried 3 times with backoff (roughly 5s + 10s + 20s = 35s total)
            # But we're testing the logic exists, not waiting for full timeout
            
            self.record_test("Retry Logic", True, f"Retry mechanism executed (elapsed: {elapsed:.1f}s)")
            return True
                
        except Exception as e:
            self.record_test("Retry Logic", False, f"Error: {e}")
            return False
            
    def test_fallback_mechanism(self) -> bool:
        """Test 7: Fallback mechanism when LMStudio unavailable"""
        logger.info("üß™ Test 7: Fallback Mechanism")
        try:
            from enhanced_engram_launcher_v2 import LMStudioClient, MockAIAnalyzer
            
            # Create client that will fail
            client = LMStudioClient(
                base_url="http://192.168.56.1:1234",
                timeout=2,
                max_retries=1
            )
            
            # Create fallback
            fallback = MockAIAnalyzer()
            
            # Try LMStudio (will fail)
            lm_result = client.query("test")
            
            # Use fallback
            fallback_result = fallback.analyze("Analyze BTC/USDT")
            
            if lm_result is None and fallback_result and len(fallback_result) > 50:
                self.record_test("Fallback Mechanism", True, "Fallback activated when LMStudio unavailable")
                return True
            else:
                self.record_test("Fallback Mechanism", False, "Fallback not working correctly")
                return False
                
        except Exception as e:
            self.record_test("Fallback Mechanism", False, f"Error: {e}")
            return False
            
    def test_enhanced_bot_init(self) -> bool:
        """Test 8: Enhanced bot initialization"""
        logger.info("üß™ Test 8: Enhanced Bot Initialization")
        try:
            from enhanced_engram_launcher_v2 import EnhancedEngramBot
            
            bot = EnhancedEngramBot()
            
            # Check attributes
            if hasattr(bot, 'lmstudio') and hasattr(bot, 'mock_ai'):
                self.record_test("Enhanced Bot Init", True, "Bot has LMStudio and fallback AI")
                return True
            else:
                self.record_test("Enhanced Bot Init", False, "Missing required attributes")
                return False
                
        except Exception as e:
            self.record_test("Enhanced Bot Init", False, f"Error: {e}")
            return False
            
    def test_message_processing_logic(self) -> bool:
        """Test 9: Message processing logic"""
        logger.info("üß™ Test 9: Message Processing Logic")
        try:
            from enhanced_engram_launcher_v2 import MockAIAnalyzer
            
            analyzer = MockAIAnalyzer()
            
            # Test command-like inputs
            commands = [
                "/start",
                "/status",
                "/analyze BTC",
                "/help",
                "hello",
                "what is bitcoin"
            ]
            
            # We can't test the full bot without Telegram, but we can test the analyzer
            all_passed = True
            for cmd in commands:
                if cmd.startswith('/'):
                    # Commands would be handled by bot
                    continue
                else:
                    result = analyzer.chat(cmd)
                    if not result or len(result) < 10:
                        all_passed = False
                        
            if all_passed:
                self.record_test("Message Processing", True, "All message types processed")
                return True
            else:
                self.record_test("Message Processing", False, "Some messages failed")
                return False
                
        except Exception as e:
            self.record_test("Message Processing", False, f"Error: {e}")
            return False
            
    def test_error_handling(self) -> bool:
        """Test 10: Error handling"""
        logger.info("üß™ Test 10: Error Handling")
        try:
            from enhanced_engram_launcher_v2 import LMStudioClient
            
            # Test with invalid URL
            client = LMStudioClient(
                base_url="http://invalid.url:9999",
                timeout=2,
                max_retries=1
            )
            
            # This should handle the error gracefully
            result = client.query("test")
            
            # Should return None, not raise exception
            if result is None:
                self.record_test("Error Handling", True, "Errors handled gracefully")
                return True
            else:
                self.record_test("Error Handling", False, "Unexpected result")
                return False
                
        except Exception as e:
            # Should not raise exception
            self.record_test("Error Handling", False, f"Unhandled exception: {e}")
            return False
            
    def run_all_tests(self):
        """Run all tests"""
        logger.info("="*80)
        logger.info("ENHANCED LAUNCHER TEST SUITE")
        logger.info("="*80)
        
        # Run tests
        self.test_imports()
        self.test_config_loading()
        self.test_lmstudio_client_init()
        self.test_mock_ai_analyzer()
        self.test_mock_ai_chat()
        self.test_retry_logic()
        self.test_fallback_mechanism()
        self.test_enhanced_bot_init()
        self.test_message_processing_logic()
        self.test_error_handling()
        
        # Summary
        total_tests = self.tests_passed + self.tests_failed
        pass_rate = (self.tests_passed / total_tests * 100) if total_tests > 0 else 0
        
        logger.info("="*80)
        logger.info("TEST SUMMARY")
        logger.info("="*80)
        logger.info(f"Total Tests: {total_tests}")
        logger.info(f"Passed: {self.tests_passed} ({pass_rate:.1f}%)")
        logger.info(f"Failed: {self.tests_failed}")
        logger.info("="*80)
        
        # Save results
        results = {
            "test_suite": "Enhanced Launcher V2",
            "timestamp": datetime.now().isoformat(),
            "total_tests": total_tests,
            "passed": self.tests_passed,
            "failed": self.tests_failed,
            "pass_rate": f"{pass_rate:.1f}%",
            "tests": self.test_results
        }
        
        output_file = Path(__file__).parent / "enhanced_launcher_test_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2)
            
        logger.info(f"‚úÖ Results saved to: {output_file}")
        
        return pass_rate >= 80.0


def main():
    """Main entry point"""
    tester = EnhancedLauncherTests()
    success = tester.run_all_tests()
    
    if success:
        logger.info("‚úÖ TEST SUITE PASSED")
        sys.exit(0)
    else:
        logger.info("‚ùå TEST SUITE FAILED")
        sys.exit(1)


if __name__ == "__main__":
    main()
